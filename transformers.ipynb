{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer,TFBertModel,TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "Some weights of the model checkpoint at /home/ning/bert_conf/tf_model.h5 were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at /home/ning/bert_conf/tf_model.h5 and are newly initialized: ['classifier', 'dropout_37']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "friend_data_path = r'/home/ning/dataset'\n",
    "bert_path = r\"/home/ning/bert_conf\"\n",
    "cache_dir=r'/home/ning/bert_conf/bert-base-uncased-cache'\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_pickle(os.path.join(friend_data_path,'friends_train.pkl'))\n",
    "test_df = pd.read_pickle(os.path.join(friend_data_path,'friends_test.pkl'))\n",
    "\n",
    "train_df = train_df[train_df['emotion'].isin([ 'neutral', 'joy', 'sadness', 'anger'])]\n",
    "test_df = test_df[test_df['emotion'].isin([ 'neutral', 'joy', 'sadness', 'anger'])]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(bert_path,'vocab_friends.txt'))\n",
    "model = TFBertForSequenceClassification.from_pretrained(os.path.join(bert_path,'tf_model.h5'),config = os.path.join(bert_path,'config.json'),num_labels=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence_with_speaker(speaker,utterance,tokenizer,sos):\n",
    "    if sos:\n",
    "        tokens = ['[CLS]']\n",
    "    else:\n",
    "        tokens = []\n",
    "\n",
    "    if speaker not in ['other','None']:\n",
    "        spk_token = '['+speaker+']'\n",
    "        tokens.append(spk_token)\n",
    "        tokens.append('[says]')\n",
    "        tokens.extend(list(tokenizer.tokenize(utterance)))\n",
    "        tokens.append('[SEP]')\n",
    "    \n",
    "    else:\n",
    "        tokens.extend(list(tokenizer.tokenize(utterance)))\n",
    "    \n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def bert_encode(dataframe, tokenizer):\n",
    "    num_examples = len(dataframe.index)\n",
    "    sentence1 = tf.ragged.constant([encode_sentence_with_speaker(s[0],s[1],tokenizer,True) for s in dataframe.values])\n",
    "\n",
    "    sentence2 = tf.ragged.constant([encode_sentence_with_speaker(s[2],s[3],tokenizer,False) for s in dataframe.values])\n",
    "    \n",
    "    input_word_ids = tf.concat([sentence1, sentence2], axis=-1)\n",
    "    \n",
    "    input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "    \n",
    "    type_s1 = tf.zeros_like(sentence1)\n",
    "    type_s2 = tf.ones_like(sentence2)\n",
    "    input_type_ids = tf.concat([type_s1, type_s2], axis=-1).to_tensor()\n",
    "    \n",
    "    \n",
    "    inputs = {\n",
    "        'input_ids': input_word_ids.to_tensor(),\n",
    "        'attention_mask': input_mask,\n",
    "        'token_type_ids': input_type_ids}\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_df['emotion']\n",
    "test_target = test_df['emotion']\n",
    "train_features = bert_encode(train_df, tokenizer)\n",
    "test_features = bert_encode(test_df, tokenizer)\n",
    "\n",
    "ems = train_target.unique()\n",
    "def convert(emotion):\n",
    "    return np.where(ems == emotion)[0][0]\n",
    "\n",
    "train_labels = np.array(list(map(convert,train_target)))\n",
    "test_labels = np.array(list(map(convert,test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_labels = 4\n",
    "epochs = 3\n",
    "weight = np.array([[sum(train_target==e) for e in ems]]*batch_size)\n",
    "weight = weight[0].sum()/weight\n",
    "sample_weight = tf.constant(weight,dtype=tf.float32)\n",
    "\n",
    "def NLL(y_true,y_pred,sample_weight = sample_weight):\n",
    "    \n",
    "    node1 = tf.nn.softmax(y_pred)\n",
    "    node2 = sample_weight*node1\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    return loss(y_true,node2)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2.5e-6)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 77s 174ms/step - loss: 0.3840 - accuracy: 0.8647 - val_loss: 0.5055 - val_accuracy: 0.8281\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_save_path = r'/home/ning/models_ckpt/'\n",
    "bert_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  save_best_only=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics)\n",
    "\n",
    "history = model.fit(train_features,train_labels,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs=1,\n",
    "                    validation_data=(test_features,test_labels),\n",
    "                    callbacks=[bert_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>previous_speaker</th>\n",
       "      <th>causal_utterance</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ross</td>\n",
       "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
       "      <td>Monica</td>\n",
       "      <td>What?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>You're a genius!</td>\n",
       "      <td>Ross</td>\n",
       "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joey</td>\n",
       "      <td>Aww, man, now we won't be bank buddies!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>You're a genius!</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>Now, there's two reasons.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>Aww, man, now we won't be bank buddies!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Hey.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>Now, there's two reasons.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                          utterance  \\\n",
       "2      Ross  Or! Or, we could go to the bank, close our acc...   \n",
       "3  Chandler                                   You're a genius!   \n",
       "4      Joey            Aww, man, now we won't be bank buddies!   \n",
       "5  Chandler                          Now, there's two reasons.   \n",
       "6    Phoebe                                               Hey.   \n",
       "\n",
       "  previous_speaker                                  causal_utterance   emotion  \n",
       "2           Monica                                              What?  neutral  \n",
       "3             Ross  Or! Or, we could go to the bank, close our acc...      joy  \n",
       "4         Chandler                                   You're a genius!  sadness  \n",
       "5             Joey            Aww, man, now we won't be bank buddies!  neutral  \n",
       "6         Chandler                          Now, there's two reasons.  neutral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [Ross] [says] or ! or , we could go to the bank , close our accounts and cut them off at the source . [SEP] [Monica] [says] what ? [SEP] \n"
     ]
    }
   ],
   "source": [
    "s = ''\n",
    "for i in tokenizer.convert_ids_to_tokens(train_features['input_ids'][0].numpy()):\n",
    "    if i != '[PAD]':\n",
    "        s+=i\n",
    "        s+=' '\n",
    "print(s)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_object= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2.5e-6)\n",
    "\n",
    "batch_size = 16\n",
    "num_labels = 4\n",
    "TPs = np.zeros(num_labels)\n",
    "FPs = np.zeros(num_labels)\n",
    "FNs = np.zeros(num_labels) \n",
    "\n",
    "def cal_score(results, label_seq):\n",
    "    for i in range(len(label_seq)):\n",
    "        a = results[i]\n",
    "        b = label_seq[i]\n",
    "        if b == a:\n",
    "            TPs[a] += 1\n",
    "        else:\n",
    "            FPs[a] += 1\n",
    "            FNs[b] += 1\n",
    "    precisions = TPs/(TPs+FPs) if TPs+FPs!=0 else 0\n",
    "    recalls = TPs/(TPs+FNs) if TPs+FNs!=0 else 0\n",
    "    \n",
    "    F1s = 2*precisions*recalls/(precisions+recalls)\n",
    "    micro_p = np.sum(TPs)/np.sum(TPs+FPs) if TPs+FPs!=0 else 0\n",
    "    micro_r = np.sum(TPs)/np.sum(TPs+FNs) if TPs+FNs!=0 else 0\n",
    "    micro_f1 = 2*micro_p*micro_r/(micro_p+micro_r) if micro_p+micro_r!=0 else 0\n",
    "    return precisions,recalls,F1s,micro_p,micro_r ,micro_f1\n",
    "\n",
    "def show_perfomence(precisions,recalls,F1s,micro_p,micro_r ,micro_f1):\n",
    "    print(\"precisions:{}\".format(precisions))\n",
    "    print(\"recalls:{}\".format(recalls))\n",
    "    print(\"F1s:{}\".format(F1s))\n",
    "    print(\"micro_f1:{}\".format(micro_f1))\n",
    "    \n",
    "    return\n",
    "\n",
    "def calc_confusion_matrix(matrix,predict,true):\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        matrix[true[i]][predict[i]] += 1\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def train(train_f,train_l,test_f,test_l):\n",
    "\n",
    "    \n",
    "    confusion_matrix = np.zeros((4,4),dtype=np.float32)\n",
    "    \n",
    "    batch_size = 16\n",
    "    num_labels = 4\n",
    "    epochs = 3\n",
    "    weight = np.array([[sum(train_target==e) for e in ems]]*batch_size)\n",
    "    weight = weight[0].sum()/weight\n",
    "    sample_weight = tf.constant(weight,dtype=tf.float32)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2.5e-6)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print(\"Training for epoch {}\".format(i))\n",
    "        for step in range(len(train_l)//batch_size):\n",
    "            train_f_batch = {'input_ids': train_f['input_ids'][batch_size*step:batch_size*(step+1)],\n",
    "                    'attention_mask': train_f['attention_mask'][batch_size*step:batch_size*(step+1)],\n",
    "                    'token_type_ids': train_f['token_type_ids'][batch_size*step:batch_size*(step+1)]}\n",
    "            train_l_batch = train_l[batch_size*step:batch_size*(step+1)]\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                prediction = model(train_f_batch,training = True)\n",
    "                pred_label = np.argmax(prediction[0].numpy(),axis=1)\n",
    "                \n",
    "                loss_value  = loss_object(y_true=train_l_batch, y_pred=prediction)\n",
    "                \n",
    "                \n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        \n",
    "            if not step%50:\n",
    "                print(\"Epoch {:03d}: Step:{:03d}//{:03d} Loss: {:.3f} \".format(i,step,len(train_l)//batch_size,loss_value))\n",
    "                print(confusion_matrix)\n",
    "                \n",
    "            test_f_batch = {'input_ids': test_f['input_ids'][batch_size*step:batch_size*(step+1)],\n",
    "                    'attention_mask': test_f['attention_mask'][batch_size*step:batch_size*(step+1)],\n",
    "                    'token_type_ids': test_f['token_type_ids'][batch_size*step:batch_size*(step+1)]}\n",
    "            test_l_batch = test_l[batch_size*step:batch_size*(step+1)]\n",
    "            prediction = model(test_f_batch,training = False)\n",
    "            pred_label = np.argmax(prediction[0].numpy(),axis=1)\n",
    "            \n",
    "            if len(test_l_batch)==len(pred_label):\n",
    "                confusion_matrix = calc_confusion_matrix(confusion_matrix,pred_label,test_l_batch)\n",
    "                            \n",
    "    return confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 0\n",
      "Epoch 000: Step:000//445 Loss: 0.994 \n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "Epoch 000: Step:050//445 Loss: 0.811 \n",
      "[[494.   2.   0.   0.]\n",
      " [190.   3.   0.   0.]\n",
      " [ 31.   2.   0.   0.]\n",
      " [ 78.   0.   0.   0.]]\n",
      "Epoch 000: Step:100//445 Loss: 0.633 \n",
      "[[1046.    2.    0.    0.]\n",
      " [ 352.    3.    0.    0.]\n",
      " [  65.    2.    0.    0.]\n",
      " [ 130.    0.    0.    0.]]\n",
      "Epoch 000: Step:150//445 Loss: 1.073 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Epoch 000: Step:200//445 Loss: 1.043 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Epoch 000: Step:250//445 Loss: 1.248 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Epoch 000: Step:300//445 Loss: 0.556 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Epoch 000: Step:350//445 Loss: 0.453 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Epoch 000: Step:400//445 Loss: 0.411 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Training for epoch 1\n",
      "Epoch 001: Step:000//445 Loss: 0.470 \n",
      "[[1582.    4.    0.    0.]\n",
      " [ 477.    3.    0.    0.]\n",
      " [ 117.    2.    0.    0.]\n",
      " [ 183.    0.    0.    0.]]\n",
      "Epoch 001: Step:050//445 Loss: 0.625 \n",
      "[[1963.  119.    0.    0.]\n",
      " [ 635.   38.    0.    0.]\n",
      " [ 141.   11.    0.    0.]\n",
      " [ 239.   22.    0.    0.]]\n",
      "Epoch 001: Step:100//445 Loss: 0.306 \n",
      "[[2397.  237.    0.    0.]\n",
      " [ 759.   76.    0.    0.]\n",
      " [ 167.   19.    0.    0.]\n",
      " [ 281.   32.    0.    0.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-67e9cb66879d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3ebd218bcc64>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_f, train_l, test_f, test_l)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1685\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5562\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5563\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5564\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   5565\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5566\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "confusion_matrix = train(train_features,train_labels,test_features,test_labels)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24cc22185e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#  69%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_target' is not defined"
     ]
    }
   ],
   "source": [
    "sum(train_target=='neutral')#  69%  4936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target=='sadness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target=='anger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target=='joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'joy', 'sadness', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = np.array([4936,1230,379,576])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.sum()/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.44266613,  5.78943089, 18.78891821, 12.36284722])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.array([[sum(train_target==e) for e in ems]]*batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight[0].sum()/weight\n",
    "weight = weight/weight[0].sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.689963  , -0.12482441, -0.53783125, -0.4852844 ],\n",
       "       [ 0.7734618 , -0.17940116, -0.55217063, -0.46465898],\n",
       "       [ 0.6775636 , -0.10690157, -0.69079584, -0.63610595],\n",
       "       [ 0.7091562 , -0.04609575, -0.18738848, -0.40678862],\n",
       "       [ 0.7497835 , -0.12705968, -0.6054592 , -0.5364008 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model({'input_ids': train_features['input_ids'][0:5],\n",
    "        'attention_mask': train_features['attention_mask'][0:5],\n",
    "        'token_type_ids': train_features['token_type_ids'][0:5]})[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7123, 115])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型，重新加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ning/models.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home/ning/models.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/home/ning/models.ckpt/')\n",
    "\n",
    "model.save_weights('/home/ning/models.ckpt/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('/home/ning/models.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights(new_model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.7381787 , -1.7181199 , -1.5035897 , -0.49402303],\n",
       "        [-0.44213945,  2.3243062 , -2.1584902 ,  0.15950564],\n",
       "        [-0.6702639 , -0.8094952 , -0.41541195,  1.723997  ],\n",
       "        [ 2.8739057 , -2.1094537 , -0.8364453 , -1.2881769 ],\n",
       "        [ 3.4454439 , -1.5704695 , -1.3068649 , -1.8356565 ]],\n",
       "       dtype=float32),)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict({'input_ids': train_features['input_ids'][0:5],\n",
    "        'attention_mask': train_features['attention_mask'][0:5],\n",
    "        'token_type_ids': train_features['token_type_ids'][0:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/ning/bert_conf/tf_model.h5 were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at /home/ning/bert_conf/tf_model.h5.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "m = TFBertModel.from_pretrained(os.path.join(bert_path,'tf_model.h5'),config = os.path.join(bert_path,'config.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.layers[0].set_weights(model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:71 return_outputs_and_add_losses\n        outputs, losses = fn(inputs, *args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:167 wrap_with_training_arg\n        return tf_utils.smart_cond(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:64 smart_cond\n        return smart_module.smart_cond(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py:54 smart_cond\n        return true_fn()\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:169 <lambda>\n        lambda: replace_training_and_call(True),\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:165 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:580 __call__\n        result = self._call(*args, **kwds)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:618 _call\n        results = self._stateful_fn(*args, **kwds)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2419 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2777 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2657 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:981 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:441 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:255 restored_function_body\n        raise ValueError(\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (10 total):\n        * {'input_ids': <tf.Tensor 'inputs_1:0' shape=(None, 115) dtype=int32>, 'attention_mask': <tf.Tensor 'inputs:0' shape=(None, 115) dtype=int32>, 'token_type_ids': <tf.Tensor 'inputs_2:0' shape=(None, 115) dtype=int32>}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='inputs/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='inputs/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-24ade8e22dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2703\u001b[0m     self._function_cache.arg_relaxed_shapes[rank_only_cache_key] = (\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[0;32m-> 2705\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   2706\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:71 return_outputs_and_add_losses\n        outputs, losses = fn(inputs, *args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:167 wrap_with_training_arg\n        return tf_utils.smart_cond(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:64 smart_cond\n        return smart_module.smart_cond(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py:54 smart_cond\n        return true_fn()\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:169 <lambda>\n        lambda: replace_training_and_call(True),\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py:165 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:580 __call__\n        result = self._call(*args, **kwds)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:618 _call\n        results = self._stateful_fn(*args, **kwds)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2419 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2777 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2657 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:981 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:441 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /home/ning/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:255 restored_function_body\n        raise ValueError(\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (10 total):\n        * {'input_ids': <tf.Tensor 'inputs_1:0' shape=(None, 115) dtype=int32>, 'attention_mask': <tf.Tensor 'inputs:0' shape=(None, 115) dtype=int32>, 'token_type_ids': <tf.Tensor 'inputs_2:0' shape=(None, 115) dtype=int32>}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='inputs/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='inputs/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (10 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics)\n",
    "\n",
    "\n",
    "m.fit(train_features,train_labels,batch_size = batch_size,epochs=epochs,validation_data=(test_features,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自己建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer,TFBertModel,TFBertForSequenceClassification,BertConfig,TFBertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "Some weights of the model checkpoint at /home/ning/models.ckpt/friendsbert_pretrained.h5 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at /home/ning/models.ckpt/friendsbert_pretrained.h5.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "friend_data_path = r'/home/ning/dataset'\n",
    "bert_path = r\"/home/ning/bert_conf\"\n",
    "cache_dir=r'/home/ning/bert_conf/bert-base-uncased-cache'\n",
    "\n",
    "ckpt_path = r'/home/ning/models.ckpt'\n",
    "\n",
    "train_df = pd.read_pickle(os.path.join(friend_data_path,'friends_train.pkl'))\n",
    "test_df = pd.read_pickle(os.path.join(friend_data_path,'friends_test.pkl'))\n",
    "\n",
    "train_df = train_df[train_df['emotion'].isin([ 'neutral', 'joy', 'sadness', 'anger'])]\n",
    "test_df = test_df[test_df['emotion'].isin([ 'neutral', 'joy', 'sadness', 'anger'])]\n",
    "\n",
    "train_df_emo = train_df[train_df['emotion'].isin([ 'neutral', 'joy', 'sadness', 'anger'])]\n",
    "test_df_emo = test_df[test_df['emotion'].isin([ 'neutral', 'joy', 'sadness', 'anger'])]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(bert_path,'vocab_friends.txt'))\n",
    "\n",
    "# model_trained = TFBertForSequenceClassification.from_pretrained(os.path.join(ckpt_path,'friendsbert_no_pretrained.h5'),config = os.path.join(ckpt_path,'config.json'),num_labels=4)\n",
    "model = TFBertModel.from_pretrained(os.path.join(ckpt_path,'friendsbert_pretrained.h5'),config = os.path.join(ckpt_path,'config.json'),num_labels=4)\n",
    "# model = TFBertForSequenceClassification.from_pretrained(os.path.join(bert_path,'tf_model.h5'),config = os.path.join(bert_path,'config.json'),num_labels=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/ning/models.ckpt/friendsbert_pretrained.h5 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at /home/ning/models.ckpt/friendsbert_pretrained.h5.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "b = FriendsBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7991dbf54cf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/envs/anaconda3/envs/tfcpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \"\"\"\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1347\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
